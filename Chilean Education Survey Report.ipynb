{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from scipy.stats import spearmanr\n",
    "import re\n",
    "pd.set_option('display.max_columns', None)\n",
    "%pylab inline \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTRODUCING OUR DATASET \n",
    "\n",
    "\n",
    "Our input consists of a survey reponse, along with some additional details about the students and their search data. \n",
    "The survey is as follows: \n",
    "1. - present background of student (applying, currently enrolled, etc) \n",
    "2. - 3 preferences of higher education (institute type, institution, level and career) \n",
    "3. - sureity of options listed in #2\n",
    "4. - annual cost estimates for studying at these institutions \n",
    "5. - monthly salary expectations (own and typical)\n",
    "6. - math and language scores (Expected in application)\n",
    "\n",
    "In the next step, we load our data into a pandas dataframe and relabel some of the columns (out of convenience). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "survey = pd.read_csv('edu_chile_survey_output.csv', header = 0, low_memory = False)\n",
    "survey.rename(columns={'rut_orig':'ID', 'q1':'q1_postsec', 'q2_tipo_1_orig':'q2_institute_type_1', \n",
    "                       'q2_tipo_2_orig':'q2_institute_type_2', 'q2_tipo_3_orig':'q2_institute_type_3', \n",
    "                       'q2_nivel_1':'q2_level_1', 'q2_nivel_2':'q2_level_2', 'q2_nivel_3':'q2_level_3', \n",
    "                       'q2_carerra_1':'q2_career_1', 'q2_carerra_2':'q2_career_2', 'q2_carerra_3':'q2_career_3', \n",
    "                       'q4_nose_1_orig':'q4_IDK_1', 'q4_nose_2_orig':'q4_IDK_2', 'q4_nose_3_orig':'q4_IDK_3', \n",
    "                       'q4_cost_1_orig':'q4_TuitionEstimate_1', 'q4_cost_2_orig':'q4_TuitionEstimate_2', \n",
    "                       'q4_cost_3_orig':'q4_TuitionEstimate_3',  'q5_mi_ing_1_orig':'q5_ownwages_1', \n",
    "                       'q5_mi_ing_2_orig':'q5_ownwages_2', 'q5_mi_ing_3_orig':'q5_ownwages_3', \n",
    "                       'q5_tip_ing_1_orig':'q5_typwages_1', 'q5_tip_ing_2_orig':'q5_typwages_2', \n",
    "                       'q5_tip_ing_3_orig':'q5_typwages_3', 'q6_math_orig':'q6_math', \n",
    "                       'q5_tip_nose_1_orig': 'q5_IDK_own_1', 'q5_tip_nose_2_orig': 'q5_IDK_own_2', \n",
    "                       'q5_tip_nose_3_orig': 'q5_IDK_own_3', 'q5_mi_nose_1_orig': 'q5_IDK_typ_1',\n",
    "                       'q5_mi_nose_2_orig': 'q5_IDK_typ_2', 'q5_mi_nose_3_orig': 'q5_IDK_typ_3',\n",
    "                       'q6_lang_orig': 'q6_lang','PSU_leng_2013': 'lang_score', 'PSU_mate_2013': 'math_score', \n",
    "                       'PSU_2013':'comp_score','SIMCEMath10':'math_10', 'SIMCELang10':'lang_10', \n",
    "                       'mom_educ_simce':'educ_mom', 'dad_educ_simce':'educ_dad'\n",
    "                      }, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DETERMINING THOSE WHO SEARCHED THE DATABASE \n",
    "\n",
    "In this next step, we create a new variable to indicate whether the student searched the database or not. This is simply done by creating a new column 'survey_participant' and labeling it as 0 (did not participate) or 1 (participated). We determine participation by seeing if there were inputs in the first search done by the user or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search_report = (survey[['search1_psu_math','search1_psu_lang','search1_area',\n",
    "                         'search1_nivel','search1_carrer']]).dropna() # columns of first search \n",
    "\n",
    "rows = list(search_report.index) # extract indexes of search_report because some rows were omitted \n",
    "r = survey.shape[0]\n",
    "results = [0] * r  # list with r zeros \n",
    "\n",
    "for row in rows: \n",
    "    results[row] = 1 # if the student participated, we change value to 1 \n",
    "\n",
    "survey['survey_participant'] = results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA CLEANING \n",
    "\n",
    "In this step, we set out to clean our data, since it contains several NaN values. We have two kinds of data - numerical and categorical. For our numerical data, we remove the rows containing NaN values and then clean it by removing characters that would not allow them to resemble float values (for example, the dollar sign). An entry such as '$4.000.000' is corrected to '4000000'. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#removing any rows that have all NaN valus \n",
    "survey = survey.dropna(axis = 0, how = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We separate our numerical and categorical columns to make them easier to work with later in the program. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numerical_inputs = ['q4_TuitionEstimate_1', 'q4_TuitionEstimate_2', 'q4_TuitionEstimate_3', \n",
    "                    'q5_ownwages_1', 'q5_ownwages_2', 'q5_ownwages_3',  'q5_typwages_1', \n",
    "                    'q5_typwages_2', 'q5_typwages_3', 'q6_math', 'q6_lang','lang_score', \n",
    "                    'math_score', 'comp_score', 'math_10', 'lang_10']\n",
    "\n",
    "categorical_inputs = ['q1_postsec','q2_institute_type_1', 'q2_institute_type_2', 'q2_institute_type_3',\n",
    "                      'q2_level_1', 'q2_level_2', 'q2_level_3', 'q2_career_1', 'q2_career_2', 'q2_career_3',\n",
    "                      'q2_inst_1', 'q2_inst_2', 'q2_inst_3', 'q3', 'q4_IDK_1', 'q4_IDK_2', 'q4_IDK_3', \n",
    "                      'q5_IDK_own_1', 'q5_IDK_own_2', 'q5_IDK_own_3', 'q5_IDK_typ_1', 'q5_IDK_typ_2', 'q5_IDK_typ_3', \n",
    "                      'educ_mom', 'educ_dad', 'schl_type', 'rbdRating']\n",
    "\n",
    "numerical_outputs = [ 'search1_psu_math', 'search1_psu_lang', 'search2_psu_math', 'search2_psu_lang', \n",
    "                      'search3_psu_math', 'search3_psu_lang', 'search4_psu_math', 'search4_psu_lang', \n",
    "                      'search5_psu_math', 'search5_psu_lang', 'search6_psu_math', 'search6_psu_lang', \n",
    "                      'search7_psu_math', 'search7_psu_lang', 'search8_psu_math', 'search8_psu_lang', \n",
    "                      'search9_psu_math', 'search9_psu_lang', 'search10_psu_math', 'search10_psu_lang']\n",
    "\n",
    "categorical_outputs = ['search1_nivel', 'search1_carrer', 'search2_nivel', 'search2_carrer',\n",
    "                       'search3_nivel', 'search3_carrer', 'search4_nivel', 'search4_carrer',\n",
    "                       'search5_nivel', 'search5_carrer', 'search6_nivel', 'search6_carrer',\n",
    "                       'search7_nivel', 'search7_carrer', 'search8_nivel', 'search8_carrer',\n",
    "                       'search9_nivel', 'search9_carrer', 'search10_nivel', 'search10_carrer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning of numerical data below, through the use of regular expressions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_numerical_inputs(sub):\n",
    "    cleaned_data = pd.DataFrame(sub)\n",
    "    for column in sub: \n",
    "        if column in ['math_10', 'lang_10']: \n",
    "            continue\n",
    "        l = []\n",
    "        x = sub[column]\n",
    "        for value in x:\n",
    "            q = re.findall(r'\\d+',str(value)) # we extract just the numbers using regular expression \n",
    "            if q ==[]: \n",
    "                l.extend([None])\n",
    "                continue\n",
    "            l.append(int(q[0]))\n",
    "        cleaned_data[column] = l\n",
    "    return cleaned_data\n",
    "\n",
    "# we call the clean inputs function to \n",
    "survey[numerical_inputs]  = clean_numerical_inputs(survey[numerical_inputs])\n",
    "survey[numerical_outputs]  = clean_numerical_inputs(survey[numerical_outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now, we focus on cleaning our categorical data. We noticed that about 23% of students dont have entries for \n",
    "their first choice of institute, level and career, 30% for their second, and 34% for their third, we make a \n",
    "transformation on our data. We convert those values to unknown, which in itself represents a (very valid) category \n",
    "of students who are not sure of their plans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Institute 1:  23.97 % and Level 1:  23.96 % and Career 1:  23.98 %\n",
      "Institute 2:  30.71 % and Level 2:  30.71 % and Career 2:  30.71 %\n",
      "Institute 3:  34.81 % and Level 3:  34.81 % and Career 3:  34.81 %\n"
     ]
    }
   ],
   "source": [
    "'''This block shows the fraction of NaN values in our categorical data. ''' \n",
    "\n",
    "print 'Institute 1: ', \"{0:.2f}\".format(sum((survey['q2_inst_1']).isnull())/\n",
    "    float(len(survey['q2_career_1']))*100),'% and Level 1: ', \"{0:.2f}\".format(sum((survey['q2_level_1']).isnull())/\n",
    "    float(len(survey['q2_career_1']))*100),'% and Career 1: ', \"{0:.2f}\".format(sum((survey['q2_career_1']).isnull())/\n",
    "    float(len(survey['q2_career_1']))*100),'%'\n",
    "print 'Institute 2: ', \"{0:.2f}\".format(sum((survey['q2_inst_2']).isnull())/\n",
    "    float(len(survey['q2_career_1']))*100),'% and Level 2: ', \"{0:.2f}\".format(sum((survey['q2_level_2']).isnull())/\n",
    "    float(len(survey['q2_career_1']))*100),'% and Career 2: ', \"{0:.2f}\".format(sum((survey['q2_career_2']).isnull())/\n",
    "    float(len(survey['q2_career_1']))*100),'%'\n",
    "print 'Institute 3: ', \"{0:.2f}\".format(sum((survey['q2_inst_3']).isnull())/\n",
    "    float(len(survey['q2_career_1']))*100),'% and Level 3: ', \"{0:.2f}\".format(sum((survey['q2_level_3']).isnull())/\n",
    "    float(len(survey['q2_career_1']))*100),'% and Career 3: ', \"{0:.2f}\".format(sum((survey['q2_career_3']).isnull())/\n",
    "    float(len(survey['q2_career_1']))*100),'%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''We now transform the missing categorical inputs to 'unknown', which becomes a category of its own. We restict our\n",
    "transformation to the responses made to question 2 because the reasoning doesn't extend to questions 1 and 3.'''\n",
    "\n",
    "q1q2q3_responses = ['q1_postsec', 'q2_institute_type_1', 'q2_institute_type_2', 'q2_institute_type_3',\n",
    "                        'q2_level_1', 'q2_level_2', 'q2_level_3', 'q2_career_1', 'q2_career_2', \n",
    "                        'q2_career_3', 'q2_inst_1', 'q2_inst_2', 'q2_inst_3', 'q3']\n",
    "\n",
    "for column in survey[q1q2q3_responses]: \n",
    "    rows = survey[column].isnull()\n",
    "    row = [i for i, x in enumerate(rows) if x]\n",
    "    survey[column].loc[rows] = 'unknown'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIMENSIONATILY REDUCTION \n",
    "\n",
    "Now that our data is clean, we consider dimensionality reduction. Instead of using the large \n",
    "number of features provided, we check to see if they can be condensed. This is done by observing the correlations between two different variables (there are some more sophisticated methods involved, but I decided to keep it simple for now). On running the code below, we noticed that there were correlations between the institution and type of institute, as well as level and career, which were good enough to mention but not really consider in our analysis since they didn't help much in the initial dimension reduction process. \n",
    "\n",
    "Note that the print line has been commented to condense the size of this notebook. The details of the correlations can be viewed by simply removing the '#' in the last line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "observed_categories = []\n",
    "for x in survey[categorical_inputs]: \n",
    "    observed_categories.extend([x]) # avoid calculating both corr(x,y) and corr(y,x)\n",
    "    col_1 = survey[x]\n",
    "    for y in survey[categorical_inputs]: \n",
    "        if x == y or y in observed_categories: \n",
    "            continue\n",
    "        col_2 = survey[y]\n",
    "        #print \"The correlation between\", x , 'and', y , 'is', spearmanr(col_1,col_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We also considered doing a dimensionality reduction on our numerical data, but the number of dimensions were not significant enough to act on it (the test scores would reduce to 3 columns instead of 7 to capture over 90% of the variation, so I decided to let it be for the time being). The wages data was too distorted for the result to be of any import, as we shall discuss later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drop_missing_numbers = survey[numerical_inputs].dropna()\n",
    "final_rows = drop_missing_numbers.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING AN INITIAL MODEL \n",
    "\n",
    "Now that we have cleaned our data, its time to do a initial analysis by running it in a model. Since the problem at hand is a typical classification problem, we consider some of the models that help us solve it. After we clean our data, models are not too hard or lengthly to implement, so we consider some different models here, including Random Forests, Logistic Regression, Adaboost classifiers, and Support Vector Machines. They cover both linear and non-linearly distributed data, which provides us with some variety in our analysis. The final_rows variable below is used to drop the rows that have NaN numerical inputs (we discussed this in the previous section). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#we extract the relevant rows into final_survey, and rename the indexes in our dataframe\n",
    "final_survey = survey.ix[final_rows,]\n",
    "default_rows = range(0,len(final_survey))\n",
    "final_survey.index = default_rows \n",
    "\n",
    "features = categorical_inputs + numerical_inputs\n",
    "\n",
    "'''We construct our final dataframe report, which will be used in our further analysis. \n",
    "We also add the participant column to it. '''\n",
    "\n",
    "report = final_survey[features]\n",
    "report['survey_participant'] = final_survey['survey_participant'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENCODING OUR DATA \n",
    "\n",
    "As we have seen earlier, there are a large number of categorical inputs that we have, which python's classifiers do not like. To resolve this issue, we encode those inputs using the scikit-learn's LabelEncoder() function, which converts them to values that a classification model will accept. We also use the StandardScaler() function to scale some of our numerical inputs for our model to run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder() # encodes categorical inputs \n",
    "nm = StandardScaler() # normalizes numerical inputs \n",
    "variables = pd.DataFrame()\n",
    "\n",
    "for column in features: \n",
    "    #print column\n",
    "    x = report[column]\n",
    "    if column == 'survey_participant': \n",
    "        continue\n",
    "    if column not in numerical_inputs: \n",
    "        le.fit(x)\n",
    "        var = pd.DataFrame(le.transform(x))\n",
    "        variables = pd.concat([variables,var], axis=1)\n",
    "    else:    \n",
    "        nm.fit(x)\n",
    "        var = pd.DataFrame(nm.transform(x))\n",
    "        variables = pd.concat([variables,var], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUNNING A MODEL \n",
    "\n",
    "Finally, after encoding our data, we run it through the different models that we chose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Classifier 0.439 %\n",
      "Random Forests 0.443 %\n",
      "Gradient Boosting 0.434 %\n",
      "Logistic Regression 0.439 %\n",
      "Support Vector Machines 0.468 %\n",
      "AdaBoost Classifier 0.433 %\n",
      "Ridge Classifier 0.447 %\n",
      "Random Forests 0.444 %\n",
      "Gradient Boosting 0.447 %\n",
      "Logistic Regression 0.445 %\n",
      "Support Vector Machines 0.457 %\n",
      "AdaBoost Classifier 0.447 %\n",
      "Ridge Classifier 0.449 %\n",
      "Random Forests 0.448 %\n",
      "Gradient Boosting 0.444 %\n",
      "Logistic Regression 0.450 %\n",
      "Support Vector Machines 0.481 %\n",
      "AdaBoost Classifier 0.441 %\n",
      "Ridge Classifier 0.430 %\n",
      "Random Forests 0.435 %\n",
      "Gradient Boosting 0.443 %\n",
      "Logistic Regression 0.434 %\n",
      "Support Vector Machines 0.467 %\n",
      "AdaBoost Classifier 0.446 %\n",
      "Ridge Classifier 0.439 %\n",
      "Random Forests 0.466 %\n",
      "Gradient Boosting 0.455 %\n",
      "Logistic Regression 0.438 %\n",
      "Support Vector Machines 0.475 %\n",
      "AdaBoost Classifier 0.449 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "methods = {\"Gradient Boosting\": GradientBoostingClassifier(), \n",
    "           \"Logistic Regression\":LogisticRegression(), \n",
    "           \"Support Vector Machines\": svm.SVC(), \n",
    "           \"AdaBoost Classifier\": AdaBoostClassifier(), \n",
    "           \"Random Forests\":RandomForestClassifier(n_estimators = 1000, n_jobs = 2), \n",
    "           \"Ridge Classifier\": RidgeClassifierCV()}\n",
    "\n",
    "initial_errors = {}\n",
    "kf = KFold(report.shape[0], n_folds = 5)\n",
    "\n",
    "for train_index, test_index in kf: \n",
    "    # we split our data into training and testing sets \n",
    "    X_train, X_test = variables.ix[list(train_index),], variables.ix[list(test_index),]\n",
    "    y_train = report['survey_participant'].ix[list(train_index),]\n",
    "    y_test = report['survey_participant'].ix[list(test_index),]\n",
    "    \n",
    "    # we run a loop over all the models that we are considering \n",
    "    for model_name in methods: \n",
    "        md = methods[model_name]\n",
    "        md.fit(X_train, y_train) # fit the model \n",
    "        y_hat = list(md.predict(X_test)) # predict output for test data \n",
    "        error = sum((y_hat-y_test)**2)/float(len(y_test))\n",
    "        if model_name in initial_errors: \n",
    "            initial_errors[model_name].append(error)\n",
    "        else:     \n",
    "            initial_errors[model_name] = [error]\n",
    "        print model_name, \"{0:.3f}\".format(sum((y_hat-y_test)**2)/float(len(y_test))), '%'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INITIAL CONCLUSIONS \n",
    "\n",
    "On running our models, we notice that the error rates are pretty high. In fact, it is close to maximum error since in a classifier, if we had 100% error, that could be fixed by simply inverting the classifier. 50% error is worst case. It seems like these state-of-the-art models didn't do a good enough job on the data set that we have, but why may that be? We investigate this case in our next section. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VARIANCE ANALYSIS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our models didn't give us desired results, we explore our input features to see if there is some insight that they could provide. We divide our data into the groups that say yes, and those that say no. A high variation between these two groups will be a good thing, as those variations will help us identify what differentiates the two groups. For example, if test scores are significantly higher for those who use the database than those who don't (not the case here), then test scores would be a good category to include in our model. We look at our different inputs in the section below (post secondary details, institute, career and level preferences, wages and cost estimates as well as test scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the two groups, and their lengths \n",
    "yes_group = final_survey.ix[final_survey['survey_participant'] == 1,]\n",
    "no_group = final_survey.ix[final_survey['survey_participant'] == 0,]\n",
    "\n",
    "yes_rows =  yes_group.shape[0]\n",
    "no_rows = no_group.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''We define a function that tells us the ratio between the counts of different categories in each feature. Simply \n",
    "put, if 9 of 10 students in the yes group list university as the first institute type choice, and 5 of 10 in the no \n",
    "do it, the function changes these values to 0.9 and 0.5 respectively. The Counter() determines the nominal counts of \n",
    "the different categories. \n",
    "'''\n",
    "\n",
    "from collections import Counter\n",
    "def normalize_ratios(a, b): \n",
    "    for key in a: \n",
    "        if key not in b: \n",
    "            continue\n",
    "        value1 = a[key]\n",
    "        value2 = b[key]\n",
    "        a[key] = round(value1/float(yes_rows),3)\n",
    "        b[key] = round(value2/float(no_rows),3)\n",
    "    return a, b \n",
    "\n",
    "for column in categorical_inputs: \n",
    "    yes = yes_group[column]\n",
    "    no = no_group[column]    \n",
    "    yes = dict(Counter(yes))\n",
    "    no = dict(Counter(no))\n",
    "    yes, no = normalize_ratios(yes, no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A close analysis of the prior results obtained will reflect variations only in the choice of institute, career, level, and sureity of choice. These are the cause of the efficiency (although somewhat low) of our initial test in the previous section (as a simple check of features significance reveals). After doing our variation study on the categorical inputs, we move onto our numerical inputs.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#computing means and standard deviations for yes and no groups \n",
    "\n",
    "yes_avg_scores = yes_group[numerical_inputs].mean(axis = 0)\n",
    "no_avg_scores = no_group[numerical_inputs].mean(axis = 0)\n",
    "\n",
    "yes_std_scores = yes_group[numerical_inputs].std(axis = 0)\n",
    "no_std_scores = no_group[numerical_inputs].std(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we list the averages of the numerical inputs, to notice that there is significant overlap between the two mean values and standard deviations between the two groups (this can be tested simply by carrying out a null hypothesis test). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YES GROUP AVG: q4_TuitionEstimate_1 3222220.31 YES GROUP SD: q4_TuitionEstimate_1 66827492.79\n",
      "NO GROUP AVG: q4_TuitionEstimate_1 2380810.00 NO GROUP SD: q4_TuitionEstimate_1 2380810.00\n",
      "YES GROUP AVG: q4_TuitionEstimate_2 3101701.40 YES GROUP SD: q4_TuitionEstimate_2 75641856.24\n",
      "NO GROUP AVG: q4_TuitionEstimate_2 2251238.06 NO GROUP SD: q4_TuitionEstimate_2 2251238.06\n",
      "YES GROUP AVG: q5_ownwages_1 909222.05 YES GROUP SD: q5_ownwages_1 16555984.18\n",
      "NO GROUP AVG: q5_ownwages_1 736014.48 NO GROUP SD: q5_ownwages_1 736014.48\n",
      "YES GROUP AVG: q5_ownwages_2 801264.07 YES GROUP SD: q5_ownwages_2 14196164.86\n",
      "NO GROUP AVG: q5_ownwages_2 538652.42 NO GROUP SD: q5_ownwages_2 538652.42\n",
      "YES GROUP AVG: q5_ownwages_3 730584.84 YES GROUP SD: q5_ownwages_3 14193306.96\n",
      "NO GROUP AVG: q5_ownwages_3 488181.70 NO GROUP SD: q5_ownwages_3 488181.70\n",
      "YES GROUP AVG: q5_typwages_1 3561499.04 YES GROUP SD: q5_typwages_1 236581117.96\n",
      "NO GROUP AVG: q5_typwages_1 552439.94 NO GROUP SD: q5_typwages_1 552439.94\n",
      "YES GROUP AVG: q5_typwages_2 692413.66 YES GROUP SD: q5_typwages_2 11837222.21\n",
      "NO GROUP AVG: q5_typwages_2 559533.58 NO GROUP SD: q5_typwages_2 559533.58\n",
      "YES GROUP AVG: q5_typwages_3 631232.61 YES GROUP SD: q5_typwages_3 11834802.44\n",
      "NO GROUP AVG: q5_typwages_3 426148.77 NO GROUP SD: q5_typwages_3 426148.77\n",
      "YES GROUP AVG: q6_math 582.48 YES GROUP SD: q6_math 101.07\n",
      "NO GROUP AVG: q6_math 573.90 NO GROUP SD: q6_math 573.90\n",
      "YES GROUP AVG: q6_lang 601.27 YES GROUP SD: q6_lang 82.90\n",
      "NO GROUP AVG: q6_lang 593.47 NO GROUP SD: q6_lang 593.47\n",
      "YES GROUP AVG: lang_score 555.31 YES GROUP SD: lang_score 91.17\n",
      "NO GROUP AVG: lang_score 545.99 NO GROUP SD: lang_score 545.99\n",
      "YES GROUP AVG: math_score 552.63 YES GROUP SD: math_score 94.30\n",
      "NO GROUP AVG: math_score 543.01 NO GROUP SD: math_score 543.01\n",
      "YES GROUP AVG: comp_score 553.72 YES GROUP SD: comp_score 85.50\n",
      "NO GROUP AVG: comp_score 544.25 NO GROUP SD: comp_score 544.25\n",
      "YES GROUP AVG: math_10 0.67 YES GROUP SD: math_10 0.86\n",
      "NO GROUP AVG: math_10 0.61 NO GROUP SD: math_10 0.61\n",
      "YES GROUP AVG: lang_10 0.68 YES GROUP SD: lang_10 0.83\n",
      "NO GROUP AVG: lang_10 0.61 NO GROUP SD: lang_10 0.61\n"
     ]
    }
   ],
   "source": [
    "# printing the different numerical input means and their standard deviations \n",
    "\n",
    "for column in numerical_inputs:  \n",
    "    if column == 'q4_TuitionEstimate_3': \n",
    "        continue\n",
    "    yes_avg = yes_avg_scores[column]\n",
    "    no_avg = no_avg_scores[column]\n",
    "    yes_std = yes_std_scores[column]\n",
    "    no_std = no_avg_scores[column]\n",
    "    print \"YES GROUP AVG:\", column, \"{0:.2f}\".format(yes_avg), \"YES GROUP SD:\",  column, \"{0:.2f}\".format(yes_std)\n",
    "    print \"NO GROUP AVG:\", column, \"{0:.2f}\".format(no_avg), \"NO GROUP SD:\", column, \"{0:.2f}\".format(no_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEKCAYAAAACS67iAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xu8XGV97/HPN4QgCOQikGACiRDA4C3eEAuVDVYKLUJo\naQ5alYiX1ynkCNILiWKT7RU8bUFF29MWIXqgSKnIpRZiahKKCl6j1ARM1EQIkh5ICEQskuR3/ljP\n7Kw92ZeZ7D2sy3zfr9cka9ZaM/PsZz3zW8/6rWetUURgZmbVN6boApiZ2ehwQDczqwkHdDOzmnBA\nNzOrCQd0M7OacEA3M6sJB/QSknSipDVFl8PKSdLPJZ1SdDnyJJ0n6T+KLkeepJMkPVR0OZ5LtQ3o\nkt4q6TuSnpK0UdK/Sjqh6HK1IiLuiYhZjecj/QKnHcQ3JD0h6TFJ/yHp1aNTWhuOpAtTW/xvSZ8f\nYPkbJa2RtE3Sv0s6PLfsWkkfHuHnT5H09+l78KSkdZI+L+nokbzvAPboohZJKyTtlPSypvm3pPlv\naPF9dko6Yk/LJOlYSXdJelzS5rTNTmv19WVQy4Au6RLgb4CPAocAhwOfBd5cZLmKIOkA4HbgU8BE\nYCrQCzwzyp9Ty7Y0SjYCHwGuaV4g6QXAvwAfBCYB3wO+NFofLGkS8E1gX+CEiDgQeBWwEnjTIK/Z\na7Q+v0UBPAi8I1eGScDxwH+1+T4jcTtwFzCZLG68D3hyhO/ZT8frNiJq9QAOBJ4C/mCIdcYBV5F9\n0R4GrgT2TstOAh4C/pysMW0E5gCnAz8BHgMW5N5rEfDPwI1kG/+7wMtzy18MLAe2APcDb84t+z3g\nx+l1DwGX5MuQpr8A7AB+ldb7szT/eOAb6X1/AJw0yN/6amDzMHX2HmB1ev//BGa3UPZrgc8B/5rq\n+5RUr38FbAB+mZbvk9Z/AdkXZgvwOLCy6LZSQNv8CPD5Aer+ntzz/dK2Pjot+w3w32nb3JrW+Tnw\np8APU33+EzBukM/8KPCDYco1HdgJnJ+23Yo0/6a0HbcAK4Bjc6+ZBNwGbAXuBT4M3N3U7pembb0G\n+KMhPn85cBnwC0Bp3oVknbBfAG9I815LtnPaQva9/AwwNi1bmf6Gbamu/ohd3+VLgE3pNfMGKcML\n0vfswCHKeVb6rm0F1gKnpvmHAremv/UnwLtzr2nEhy8CT6Q6FrAAWAf8P7LYMSGtv09a97H0d94H\nHNxyGyu6kXfgS/O76UswZoh1PpwaxgvS4xtAb1p2EvAsWY9pL+DdqdKvT1+2Y4Gngem5DfYMcHZa\n/0+Bn6XpsWnDX5qmT06N7aj02keA30rT49kVSE8CfpEr78+Bk3PPX5g2+O+m529Mz18wwN96QCr/\ndcBpjYaTW/5HqdG/Kj0/AjishbJfmxrc8bmGeCXwlfS3PD818o+l5R8nC/BjUt2cUHRbKaBtDhTQ\nrwI+2zTvR8DZuXr+cNPyn5MF0cnABLKd8XsH+cxvAX85TLkaAf06sp58Yyc8L7X5vcmOeH+Qe82N\n6fE84CVkHaO707L9yALxO8iC1yvIOkcvHuTzl5MFujtzbfo+4HWpbTYC+quA49J7Hk7WGXpf7n12\nAi/KPW98lxelNnc62c5y/CDleJCs03EWcEjTsuPIAvIp6fmhwNFp+m6yncveub+1pyk+vDn3PbmI\nLP4cml7zt8ANafl70/dmn/R3vhLYv+U2VnQj78CX5q3AI8Oss67RcNLzU4Gf5RrBr9jVU9g/NZTX\n5Nb/LnBmboN9M7dMZD2BE4ATm8sC3ND4ggHryXphBzStM1BAPyX3/C+AJU2vuRN4+yB/7zHA59OX\n7DepwRyce93/GuA1w5X9WuC6puXbmr5Qr8/Vay9wC3Bk0W2kwLY5UED/R+DjTfPuAd6Rq+eBAvpb\ncs+vAD43yGeuJRfsydKOW8h2znemedPJeqfThyj7hPQ9OIBsp/wb0s49Lf8YuwL6XJqOwIC/Az40\nyHs3AvpbUxs7BnggLesL6AO87iLgX3LPdwJH5J43vstjcvM2AccN8n4vBD6d6mw7Wa//yFz5/3qA\n10wj22nsl5v38cZ2JosPK5pes5r+HbRDU32OAd6Ztv/L9qSN1THv+Thw0DA53ReSBbeGDWle33tE\nqmng1+n/fC7v12SBvqHvTHp63cb0fi/ML8t91tQ0/YfA7wMbJC2XdPwQZc6bDsxNJ242S9pCtgM5\ndKCVI+LBiDg/Ig4HXprKdVVafBjw0wFeNlzZyS+XdDBZz+x7jXIB/0Z2BATwv9PnLE0n5S5t8W+t\nu21kacK88WRprKFsyk0/Tf/2mPc4uXYREbdHxETg/WQpsryHGxOSxki6PG2rJ8h2IgEcBBxM1uN9\nOPfaDbnp6cDxTe3zrcCUYf6mW8hSd/PJ0g79SDpK0u2SfpnK9LFUnqE8HhE7c88HrauIeCQi3hcR\nR6W/4VdkKU8Y+nuyOSKezs0b9HuSTAduyX1PVpPtFCaT/d13ATdKejhtg5bz7nUM6N8iO8SZM8Q6\nG8kqtWE6WfpjTx3WmJAksr32I+lxeNO6h6fPJyK+FxFzyL4gt5LlLAcSTc8fAr4QEZPSY2JEHBAR\nnxyuoBHxE7JD65fm3uvIAVZ9JP93NZd9gHI9RvZleUmuXBMiYnz63G0R8WcRcSRwJnCJpJOHK28X\n+DEwu/FE0vPJtsd/plnN275d/87Q34W8/Ge9law3f0pETABmkB19iiyFt53+7SPfzh8i65Xm2+eB\nEXHhkB8e8WuyTsD/ZFcgzftbsnz8kalMH0zlGXURsZEsh9/K92RS2m4NQ31PIOtMnt5UP8+PiF9G\nxPaI+EhEvAT4LbJt8A5aVLuAHhFPkh3mfFbSWZL2lTRW0umSLk+r3QhcJukgSQcBH2KAHkEbXi1p\nTtqTvp/sJNa9ZHnAX0n6i1SGHuAM4J8k7Z2GVh4YETvIemQ7Bnn/R8ly2w3/F3izpFNTT+p5aczt\nC5tfKOkYSZdImpqeHwa8hWzHB9kh/59JelVafmRa5z7g6YHKPlAB05HJPwBXpd46kqZKOjVN/76k\nxhfiKbKAsHOg96obSXtJeh7pvIqkfXK9rluAl0g6W9I+ZG13VUSsTcs30X/bt+tvgImSvtgY0pdG\nPs1uWq85MB5A1jHakoLVJ0iBKfV4vwwsTt+vY4Hzcq+9Azha0ttS29lb0mskvbiF8i4kO8E/0Pjx\nA4AnI+Lp9F5/0rS8+XvSMkkTJC1O7V8pLpzPru/JNcA7JZ2clr9Q0jER8TBZPvwTabu+HHgXQ8eT\n/wN8XGl4qqSDJZ2ZpnskvTRlGLaR9dxb/57sSZ6mCg+yoPUdsuDxCNnJjvwJvKvS/I1kJ/PGxa68\nWz5/vRdZoD08N+9u4K2xK0d2E1mge5Js2NkrcuvOIhsh8ARZr6uRe9+brDfyeFp2H/D6QcpwJtlh\n3GZ2jYR5bXrfx8m+9LcD0waohxeSDYN7ONXFQ2QnJ/fPrfNe4IFU/h81yj9Y2dOyz7N7bncc2WHw\nT9NrfgzMT8suJjtsf4qsh/KBotvIc9gWF5F9KXfkHn+ZW34KWc/zV8DXm9raTLKRFZuBL6d5P6P/\nOZVFZEdsg33+FLKd7SNpG68ly80fk5Y3cuj5XPPzyU5wP5m229vSOkek5QelNvcEWeell/6jXI4i\nC+z/RdajX0Zu9FdT+b4OnD/Isvwol99O9fQkWX57cdNnvjf9jZuBc2j6Hg1Ud7n5+5Eduf4svf8j\nZAMhDs2tcxbZyKInyUazvCnNn5rq4vFUt+8ZatuQ7TwvJvvONUbMfDQtOzfNf4pshNGVDDHAo/nR\nOPE3JEkXkY32APiHiPi0pIlkgWI62cm9uRGxNa2/kGzvth24KCKWDvshFSVpEdkhYMuHRVZNqQd9\nN9mOaxzZMMIPFFsqs12GTblIegnZIcRryA7TzkiHzguAZRFxDNkedmFa/1iys9yzyIYJfS7llc0q\nLSKeIRud8Erg5cApqsjVx9YdWsmhzwLui4hnIsv13g38AVkaYElaZwm7TrycCdwYWXJ/PdnhxHGj\nWmqzgsSu0Qz7kH1/thRYHLN+Wgno/wn8tqSJkvYju7rxMGByRGwCiIhHyS6VhSyflD+hsZH+Q3hq\nJSJ6nW7pHukk9A/ITsCtiIjVRZfJrGHYgB4RD5BduPA14KtkJ2gGGo0x0uFVZqUXETtTymUa8AZJ\nJxVdJrOGsa2sFBHXkp0VR9LHyHrgmyRNjohNkqaw68KbjfQfnzqN/mMySe/jHYB1XER0apzyk5L+\nlezc0sr8Mrdt67TB2nVL49Bz44oPJ7tnyQ1kN+aZl1Y5j+zCGNL8cyWNk/QismFX3x6kUKV7LFq0\nqPAyVOlR5voabem6hfFpel+yuxWuctuu56Os9TWUlnrowL8ou53ls8AFkfVOrgBuktS4Q9vc1JBX\nS7qJXZezXhDDlcKsGg4FlqRRW2OAL0bEvxdcJrM+raZcdrvBfERsBn5nkPU/QXZlmVltRMT9ZHf8\nMyul2l36P1I9PT1FF6FSXF/V4W3VnirWV0tXinbkgyVnYqyjJBEdOik6zOe6bVvHDNWu3UM3M6sJ\nB3Qzs5pwQDczqwkHdDOzmnBANzOrCQd0M7OaaPVKUTOroKF+isBDK3dX9fpyQDersXwQkqACMalQ\nVa8vp1zMzGrCAd3MrCYc0M26xKJFRZfAOs0BvcmKFSuKLoJZRyxeXHQJqqWKO0AH9CYO6GYG1dwB\nOqA3Wb9+fdFFMDPbIx62SNYrb/TMlyxZwowZM4DsfshVvCeymXUn3w+9SU9Pj9MuNeH7oVsdDdWu\n3UOnfw995cqVLE7JM/fQhzd//nyuvvrqoothLVi8uJp5YWude+hNZs6cybp164ouRmXMmDGjtOcd\n3EPvr4pXPhaprDvAodq1A3qTMgeoMjrggAN46qmnii7GgBzQ+3NAb09Z68spl2HkUy4bNmxwymUY\n8+fP54477gBg27ZtfSeRzzjjDKdfzArkgG5tu/rqq/sC95gxY3xEY1YSLaVcJC0E3gbsAO4H3gk8\nH/gSMB1YD8yNiK259c8HtgMXRcTSAd6zlIelY8eOZfv27UUXo9TyPfQNGzYwffp0oHw9dKdc+itr\nCqGsylpfI0q5SJoOvAd4cUT8RtKXgLcAxwLLIuKTki4FFgILJB0LzAVmAdOAZZKOKmULT/IBaseO\nHU4hDOOcc87hoIMOAqC3t5d58+YBOD1VclW8lN3aM2wPXdJE4FvA64GngC8DnwauBk6KiE2SpgAr\nIuLFkhYAERFXpNf/G7A4Iu5ret/SxPh8Dr23t5dFqeU7hz681FsouhgDcg/dRqK2o1wkvQf4G+Bp\nYGlEvF3SloiYmFtnc0RMkvQZ4FsRcUOa/4/AVyPiy03vWcpGX+YAVRZV2QE6oFsdjTTlcgTwfrJc\n+VbgnyX9MdDcYttuwYtzu7+yBQMb3M0339yXogK47rrrAHjssccK3Yb5HY1ZN2ol5TIXeFNEvCc9\nfztwPHAK0JNLuSyPiFkDpFzuBBaVOeVy9tlns3z5cgC2bt3K+PHjATj55JO55ZZbiixa6U2YMIEn\nnnii6GIMaLR76JKmAV8AJgM7gX+IiE8PsF5p2rbVz0jHoT8IfEjS84BngDcC3wG2AfOAK4DzgFvT\n+rcB10u6EpgKzAS+PZI/oNNOOukktmzZAmSX/s+ePbtvvg0s/2O6+emaB7LtwCURsUrS/sD3JC2N\niAeKLpgZtHD73Ij4IVmv5HvADwEBf08WyN8k6UGyIH95Wn81cBOwGvgqcEHZuyuzZ8/ul/JpTDcC\nu+0uIogILrzwwr7pkm/mEYuIRyNiVZreBqwh67RUQhlP8Nno8qX/Tfbdd19+/etfF10MGwWdPCkq\naQawAnhpCu75ZaVs22UdV11WVRzl4h+4aOI0iw0npVtuJrtobttw61s19fYWXYL2+dL/pEtzwtYm\nSWPJgvkXI+LWwdbzCC4bLe2M3nLKpYkPS+ujEykXSV8AHouIS4ZYx227BspaX065WMeUMcfYKZJO\nAP4YOEXSDyR9X9JpRZfLrME99CZl3SuXVZnry1eK9lfWk3xlVda27R66mTmYt6mKNzNzD71JWffK\nZVXm+nIP3erIPfQ2VHGvbGYG7qHbCLmHPuDnum1bx7iHbh3jIxqz8nBAtxHxibbq8LaqPwd0sy5R\nxUvZi1TFHaBz6FZbzqH3V+bzHWVU1vpyDr0NVdwrm5mBe+i7Kete2drnHnp/btvtKWt9uYduHeMj\nGrPycEC3EfGJturwENP6c0A36xI+mmpPFXeAzqE3KWverKzKXF/OoVsdOYfehirulc3MwD10GyH3\n0Af8XLdt6xj30K1jfERjVh4O6DYiPtFWHd5W9TdsQJd0dO73E38gaauk90maKGmppAcl3SVpfO41\nCyWtlbRG0qmd/RPMrBUeYtqeKu4A28qhSxoDPAy8DpgPPB4Rn5R0KTAxIhZIOha4HngtMA1YBhzV\nnFR0ntE6zTn0/sp8vqOMylpfo5lD/x3gpxHxEHAWsCTNXwLMSdNnAjdGxPaIWA+sBY5ru9QFqeJe\n2cwM2g/o/wO4IU1PjohNABHxKHBImj8VeCj3mo1pXiX4sNTMqmpsqytK2pus931pmtV8MNL2wcni\nXHe4p6eHnp6edt/CCrZ4cXmOalasWMGKFSuKLoZZYVrOoUs6E7ggIk5Lz9cAPRGxSdIUYHlEzJK0\nAIiIuCKtdyewKCLua3o/5xlroMz11a059EmTYMuW1tefOBE2b+5ceaqqrG17tHLobwH+Kff8NmBe\nmj4PuDU3/1xJ4yS9CJgJfLutEpvZHtuyJQtErT7aCf51NGlSFrybHzDw/EmTii3vUFrqoUvaD9gA\nHBERT6V5k4CbgMPSsrkR8URathB4F/AscFFELB3gPd1Dr4Ey11e39tDb3SZl3obPharV11Dt2pf+\nNylTTrgKim7cQ3FA78z6dVO1+nJAt44punEPxQG9M+vXTdXqy/dysY7xvVzMysM9dKutTvTQJV0D\nnAFsioiXD7KOe+gVUrX6cg/dbPRcC/xu0YUwG4gDulkbIuIeoMsH+llZOaA38QgXM6uqli/97xa9\nvQ7qNnK+rYWNlnZuaeGTok2KPuFRNWUet9+pYYuSpgO3+6RoPVStvjwOvQ1Fb6yqKXN9dTCgzyAL\n6C8bZLkDeoVUrb48ysVslEi6AfgmcLSkX0h6Z9FlMmtwD71J0XvfqilzfflK0c6sXzdVqy/30Nvg\nKx/NrKrcQ7cRKbq3MhT30Duzft1Urb7cQ7eO8RGNWXm4h2615R56Z9avm6rVl3voZmZdwFeKmtVM\nIGjjuCRy/1q1uYfepKxXPZq1SrTxg6IR2fpWC86hNyk6P2ajxzn0zqxfO9qDJlLo9nUO3TrERzRW\ndXU6onEPvUnX91baVOb6cg+9M+vXTdXqyz10M7Mu4IBuZlYTLQV0SeMl/bOkNZJ+LOl1kiZKWirp\nQUl3SRqfW3+hpLVp/VM7V/yRmTQpO3zKP2D3eVK2rplZmbXaQ/8U8NWImAW8AngAWAAsi4hjgK8D\nCwEkHQvMBWYBpwOfk/bkNHLnbdnS+rmQLf4VSTMruWEDuqQDgd+OiGsBImJ7RGwFzgKWpNWWAHPS\n9JnAjWm99cBa4LjRLrg993xEY1ZurfTQXwQ8JulaSd+X9PeS9gMmR8QmgIh4FDgkrT8VeCj3+o1p\nnlWcj2jMyq2VS//HAq8CLoyI70q6kizd0jxwp+2BPP4hXRtN7fyYrlkdDTsOXdJk4FsRcUR6fiJZ\nQD8S6ImITZKmAMsjYpakBUBExBVp/TuBRRFxX9P7Fj4OvZ3xpEWPPS2DqtWXx6F3Zv26qVp9jWgc\nekqrPCTp6DTrjcCPgduAeWneecCtafo24FxJ4yS9CJgJfHvPi29mZq1o9W6L7wOul7Q38DPgncBe\nwE2Szgc2kI1sISJWS7oJWA08C1xQeFfczKwLdPWl/1VLIRStavXllEtn1q+bqtWXL/03M+sCDuhm\nZjXhgG5mVhMO6GZmNeGAbmZWEw7oZmY14YBuZlYTDuhmbZB0mqQHJP1E0qVFl2cwA90Bc7DHxIlF\nl9ZGiy8sqtCFMkWrWn2N9oVFksYAPyG7/cUjwHeAcyPigab1Cm/bAynDNikjX1hk1p2OA9ZGxIaI\neBa4kex3AcxKodV7udRSIGix/xa5f61rNd/r/2H84y210M5vqpU5RdXVAV1EeymEzhbHasT3+q+O\nwWJA0amVhnbu8+8ceoVywkWrWn11IId+PLA4Ik5Lz/vd+z+3XuFteyBl2CZVUtb6cg7dRkWWomrt\nEa3msqrlO8BMSdMljQPOJbv/fyUsWlR0CazT3EOvUI+zaFWrr07cPlfSacCnyDpD10TE5QOsU3jb\ntpErQxseyFDt2gG9QgGqaFWrr269H7qNjjK04YE45WJm1qYqpqjcQ69Qj7NoVasv99CtjtxDNzPr\nAg7oZl0iNzTeasoplwqlEIpWtfpyyqW/MmwTGzmnXMzMuoADupnZAKqYomop5SJpPbAV2Ak8GxHH\nSZoIfAmYDqwH5kbE1rT+QuB8YDtwUUQsHeA9Cz8srVoKoWhVqy+nXPorwzapkrLW12ikXHYCPRHx\nyoho3F1uAbAsIo4Bvg4sTB92LDAXmAWcDnxOaudeZmZmtidaDegaYN2zgCVpegkwJ02fCdwYEdsj\nYj2wFt9i1KxwVbxQxtrTakAP4GuSviPp3Wne5IjYBBARjwKHpPnN94zemOaZWYGqmBO29rR6P/QT\nIuKXkg4Glkp6kN1vD952tsn3jLbR1M59o83qqO1x6JIWAduAd5Pl1TdJmgIsj4hZzfeIlnQnsCgi\n7mt6n8JPHLX7KyWbN3euLFXgk6Itf27hbdtGbvHich7VjOhui5L2A8ZExDZJzweWAr1kP5S7OSKu\nSL9+PjEiFqSTotcDryNLtXwNOKq5hZe10ZchEJWVA3rLn1vKtm31MFS7biXlMhm4RVKk9a+PiKWS\nvgvcJOl8YAPZyBYiYrWkm4DVwLPABW7dZmad19WX/g+kDD3LsnIPveXPLWXbLmsKwdrjH7hoQxkC\nUVk5oLf8uW7b1jEjTbmY9Wn1RPLEiZ0th5ntzvdyaeKLLwYXsftjsPndPiLIqq+K6SmnXGxEynwY\n75RLf2XeVmVU1vry7XPNzLqAA7pZl3A6sf6ccrERKethKTjlYiNT1rbtlIt1jHt9ZuXhgN6kime2\ni+T6srqqYmfFKZcmZT3MsvY55WJ15JSLmVkXcEA36xJOj9WfUy5NnHKpj9FMuUg6B1hM9lu5r42I\n7w+xrtu2dYxTLtYxXdTrux84G1hZdEHMBuOA3qSKZ7aL1NtbdAmeGxHxYESsJfvBdOsCVeysOOVi\nI1Lmw/hOjHKRtBz4U6dc6q+s9eXb55q1QNLXyH6hq28W2Y+ffzAibm/nvfwD6DZa2vnxc/fQbUTK\n2osB99Cb+ReL2lPWtu2Tomajq5J5dAfz+nNAtxHplpPIkuZIegg4HrhD0r8VXSazZg7oTdyLaU+3\n1FdEfCUiDouIfSPi0Ig4vegyWWdVsbPiHHqTsubNrH2+l4vVkXPoZmZdoOWALmmMpO9Lui09nyhp\nqaQHJd0laXxu3YWS1kpaI+nUThTczNrTLemxbtZyykXS+4FXAwdGxJmSrgAej4hPSroUmBgRCyQd\nC1wPvBaYBiwDjmo+Bi3rYalTLvXhlEt/btv1MOKUi6RpwO8B/5ibfRawJE0vAeak6TOBGyNie0Ss\nB9YCx+1Bua0C3OszK49WUy5XAn9OdtVcw+SI2AQQEY8Ch6T5U4GHcuttTPMqoYpntovULfdyse5T\nxc7KsJf+S/p9YFNErJLUM8SqbR/MlfHy6CpuRMu0c4m02XB6e6sXD4bNoUv6OPA2YDuwL3AAcAvw\nGqAnIjZJmgIsj4hZkhYAERFXpNffCSyKiPua3reUeUZrT5nzss6h91fmbVVGZa2vEeXQI+IDEXF4\nRBwBnAt8PSLeDtwOzEurnQfcmqZvA86VNE7Si4CZwLdH+DeY2Qg5nVh/I7nb4uXATZLOBzYAcwEi\nYrWkm4DVwLPABaXsrph1maqlD6x9vlLURqTMd/BzysVGopYpl25T1uBUVq4vq6sqpqjcQ29S1r2y\ntc89dKsj99DNzLqAA7pZl3B6rP6ccmnilEt9OOXSn9t2PTjlYh3jXl+VnF10AazDHNCbVPHMdpF8\nL5cqubPoAlRKFTsrTrnYiJT5MN4pl6wOBlOWMpZVWdu2Uy5mXWrOnDmMHz+e8eOz359pTM+ZM2eY\nV1oVjeTSfzMruZNOOoktW7YAsHLlSmbPnt033+rHKRcbkbIeloJTLgAnnngi3/3udwF45pln2Gef\nfQB4zWtewz333FNk0UqvrG17qHbtHrqNiE8il9s555zD2LHZ13zlypUcf/zxAE65tORssjuFV4dz\n6E2qeGa7SK6vclu3bh3r169n/fr1AH3T69atK7ZgFbDXXtUbFeSA3sTD8KxOZs6cyYwZM5gxYwZA\n3/TMmTOLLVhJSep77Njx3/2eV4EDuplZUvVRQc6hm5klVR8V5IC+m/nA1UUXwswKcM0117BmzZq+\n542RQI8//jgXX3xxUcVqmQP6bpbggN66Mv9i0WiS9EngzcAzwE+Bd0bEk8WWykbbZz7zGVasWAFA\nb28vl112GQA9PT3FFaoNDuhJ/qRHfros44nLqre3OwI6sBRYEBE7JV0OLEyPUps9ezZPPPEEkKUQ\nGoGpkUqw/latWtUX0IG+6QkTJlQiqDugA/Pnz2f69OkAbNiwoW/6jDPOKLJYViIRsSz39F7gD4sq\ni3XOzTff3HchFsC9994LwPbt251yMaup84Ebiy5EK6re43yuHXzwwTzvec8DsitrG9MHH3xwkcVq\nmQM62aHoww8/3Pe8Mb1y5cqiimQFkPQ1YHJ+FhDAByPi9rTOB4FnI+KGAorYNqdc2uNRLjVw//33\n901LYvv27QWWxooSEW8aarmkecDvAacM916LcycWenp63BuuiJUrV7Jq1aq+543piRMnFpZyWbFi\nRb+jrKFl+q6yAAAHpElEQVQMe3MuSfsAdwPj0uPWiPiApInAl4DpwHpgbkRsTa9ZSHZYuh24KCKW\nDvC+pbmB0dlnn83y5csB2Lp1a99FBSeffDK33FKtezk818o8ymU0b84l6TTgr4E3RMTjw6xbmrY9\nf/587rjjDmD380NXX+3RXM3ywbO3t5dF6WZFZdopj+jmXBHxjKSTI+JpSXsB35B0AnAmsCwiPinp\nUrIz/gskHQvMBWYB04Blko4qTQsfwNSpU5kwYQKQBfTG9NSpU4ssViWUNZh3wGfIOjRfS6Og7o2I\nC4ot0vDOOeccDjroICALUPPmzQOqMwzvufapT32qr3MHcNVVVwHwwx/+sBJ11lLKJSKeTpP7kN0u\nYAtwFtBILC0BVgALyAL9jRGxHVgvaS1wHHDf6BV7dLnR23Ai4qiiy7AnfFK0PevWrWPbtm19zxvT\nVbmZWUsBXdIY4HvAkcDfRcRqSZMjYhNARDwq6ZC0+lTgW7mXb0zzSuuyyy7rN1Tp8ssvB2DZsmW+\nZ/Qw5s+f70N3q413vetdfOUrXwGyfPqJJ54IVOd2w6320HcCr5R0IHCXpB6ys//9Vmv3w8ty4mj2\n7Nl9I1s2bNjAlClT+ubb0G644YbSBPR2Th51i4svvrjvZN64ceNcPzXX9i8WSfoQ8GvgXUBPRGyS\nNAVYHhGzJC0AIiKuSOvfCSyKiPua3qeUafV0wqHoYlTGuHHj+M1vflN0MQbkXyzqb9KkSWzevLno\nYpRa7U+KSjqIbNztVkn7Am8CeoHbgHnAFcB5wK3pJbcB10u6kizVMhP49kj/iE5q7tk1jhzKtBHL\nZP78+Xz2s5/te+5bJZRXvm1v2bLFbbvmWhm2+DKyk54iOyH6xYj4K0mTgJuAw4ANZMMWn0ivWUjW\ng3+WCgxbzNtvv/14+umnh1+xi1111VX98oyNiy7mzJlTqsuj3UPvb/Hixf3SnDa0sWPHlvKalJEO\nW7wfeNUA8zcDvzPIaz4BfKLNcpZCGTdg2fjqw2pq/AydDS5/RLNjx47KHdH4SlH69zifffbZvg1X\nth5nWdx88819F6sAXHfddQA89thjlWj03Wr16tVFF6H0qj7Ms+2ToqP2wSU6LK3CiZCyKvNJZKdc\n+psxY4Z76W2YMGFC35FomYwo5dIN3ONsj08iV0d+W23YsMHbahj5+tq6dWvl6ss99CZlHoZXRu6h\nD/i5pWnbVTmBXUYzZ84s5RWiQ7VrB/Qm+++/f79Lf213VbmZmQN6f065tKenp6eUF2I55dKGadOm\nFV2E0rvooot4xSteAWTnHBo9vSocknazxk3nbHD5lMvKlSsrl3JxQKf/RnzwwQcrtxHNWtG46ZwN\nrvk7X7Vx+065NCnrYVZZ7bXXXuzYsaPoYgzIKRcbibJeiOWUyzCqfpj1XMufaNu5c6fH7VstVfG7\n7x56k3nz5vUNW7ThlfmGT+6hWx25h96GGTNmFF2E0vMNn8zKyT30JitWrHBQakNZx+qCe+hWT+6h\nt8HBfHj5HvpPf/pT99DNSsI9dBuRMp9zcA/d6miodj3muS6M1YvPOZiVhwO6jYhTLGbl4ZSL1ZZT\nLlZHTrmYmXUBB3Qzs5pwQDczqwkHdDOzmnBANzOriWEDuqRpkr4u6ceS7pf0vjR/oqSlkh6UdJek\n8bnXLJS0VtIaSad28g8wey5I+rCkH0paJWmZJP8SipVOKz307cAlEfES4PXAhZJeDCwAlkXEMcDX\ngYUAko4F5gKzgNOBz0l6zoeO7SnfC709XVRfn4yIV0TEbOBWYHHB5WlbF22rUVHF+ho2oEfEoxGx\nKk1vA9YA04CzgCVptSXAnDR9JnBjRGyPiPXAWuC4US53x1RxIxapW+ortf2G5wOPFVWWPdUt22q0\nVLG+2ro5l6QZwGzgXmByRGyCLOhLOiStNhX4Vu5lG9M8s0qT9FHgHcDTwOsKLo7Zblo+KSppf+Bm\n4KLUW2m+FM6XxlmlSfqapB/lHven/98MEBGXRcThwLXAVcWW1mwAETHsg6wnfydZMG/MW0PWSweY\nAqxJ0wuAS3Pr3Qm8boD3DD/86PSjlfbd7gM4DLh/iOWF/91+1PsxWNtrNeXyeWB1RHwqN+82YB5w\nBXAe2YmixvzrJV1JlmqZCXy7+Q2LuMeG2Z6SNDMiGr/kMQdYNdi6bttWlGFvziXpBOBu4H527SE+\nQBakbyLrrWwA5kbEE+k1C4F3Ac+S9eqXduoPMHsuSLoZOBrYAfwM+JOI+K9iS2XWX2F3WzQzs9Hl\nK0UTSddI2iTpR0WXpQoGu+DMysdtuz1VbtvuoSeSTgS2AV+IiJcXXZ6ykzQFmBIRq9IIqO8BZ0XE\nAwUXzZq4bbenym3bPfQkIu4BthRdjqoY5IIzX29QQm7b7aly23ZAtxHLXXB2X7ElMRtdVWvbDug2\nIgNccGZWC1Vs2w7otsckjSVr8F+MiFuHW9+sKqrath3Q+1N6WGsGuuDMysltuz2VbNsO6ImkG4Bv\nAkdL+oWkdxZdpjJLF5z9MXCKpB9I+r6k04oul+3Obbs9VW7bHrZoZlYT7qGbmdWEA7qZWU04oJuZ\n1YQDuplZTTigm5nVhAO6mVlNOKCbmdWEA7qZWU38f29q6maZ8aFlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1098bdb90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We create boxplots to present the opinion that the numerical inputs are largely not helpful \n",
    "\n",
    "fig , ax = plt.subplots(1,2)\n",
    "ax[0].boxplot([yes_group['comp_score'],no_group['comp_score']]); \n",
    "ax[0].set_title('Composite Scores');\n",
    "ax[1].boxplot([yes_group['math_10'],no_group['math_10']]);\n",
    "ax[1].set_title('10th Grade Math Scores');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the story is pretty much the same for all the other numerical inputs. Similar means and/or very high variances exist that create an overlap between two data sets. As a consequence, these features pass the null hypothesis test and do not provide any support in our study. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPLEMENTING MODELS WITH FEWER FEATURES\n",
    "\n",
    "Now that we have determined that a large fraction of our input variables are of not much use, we run the same models from earlier with fewer features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We encode our features in this block of code \n",
    "\n",
    "features = q1q2q3_responses\n",
    "\n",
    "le = LabelEncoder() # encodes categorical inputs \n",
    "nm = StandardScaler() # normalizes numerical inputs \n",
    "variables = pd.DataFrame()\n",
    "\n",
    "for column in features: \n",
    "    #print column\n",
    "    x = report[column]\n",
    "    if column in ['survey_participant', 'q1_postsec']: \n",
    "        continue\n",
    "    if column not in numerical_inputs: \n",
    "        le.fit(x)\n",
    "        var = pd.DataFrame(le.transform(x))\n",
    "        variables = pd.concat([variables,var], axis=1)\n",
    "    else:    \n",
    "        nm.fit(x)\n",
    "        var = pd.DataFrame(nm.transform(x))\n",
    "        variables = pd.concat([variables,var], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Classifier 0.450 %\n",
      "Random Forests 0.479 %\n",
      "Gradient Boosting 0.462 %\n",
      "Logistic Regression 0.449 %\n",
      "Support Vector Machines 0.459 %\n",
      "AdaBoost Classifier 0.467 %\n",
      "Ridge Classifier 0.465 %\n",
      "Random Forests 0.470 %\n",
      "Gradient Boosting 0.454 %\n",
      "Logistic Regression 0.466 %\n",
      "Support Vector Machines 0.460 %\n",
      "AdaBoost Classifier 0.462 %\n",
      "Ridge Classifier 0.470 %\n",
      "Random Forests 0.484 %\n",
      "Gradient Boosting 0.468 %\n",
      "Logistic Regression 0.470 %\n",
      "Support Vector Machines 0.477 %\n",
      "AdaBoost Classifier 0.470 %\n",
      "Ridge Classifier 0.454 %\n",
      "Random Forests 0.476 %\n",
      "Gradient Boosting 0.454 %\n",
      "Logistic Regression 0.453 %\n",
      "Support Vector Machines 0.459 %\n",
      "AdaBoost Classifier 0.457 %\n",
      "Ridge Classifier 0.476 %\n",
      "Random Forests 0.483 %\n",
      "Gradient Boosting 0.459 %\n",
      "Logistic Regression 0.476 %\n",
      "Support Vector Machines 0.475 %\n",
      "AdaBoost Classifier 0.468 %\n"
     ]
    }
   ],
   "source": [
    "# We run our model in this block of code \n",
    "\n",
    "kf = KFold(report.shape[0], n_folds = 5)\n",
    "final_errors = {}\n",
    "for train_index, test_index in kf: \n",
    "    # we split our data into training and testing sets \n",
    "    X_train, X_test = variables.ix[list(train_index),], variables.ix[list(test_index),]\n",
    "    y_train = report['survey_participant'].ix[list(train_index),]\n",
    "    y_test = report['survey_participant'].ix[list(test_index),]\n",
    "    \n",
    "    # we run a loop over all the models that we are considering \n",
    "    for model_name in methods: \n",
    "        md = methods[model_name]\n",
    "        md.fit(X_train, y_train) # fit the model \n",
    "        y_hat = list(md.predict(X_test)) # predict output for test data \n",
    "        error = sum((y_hat-y_test)**2)/float(len(y_test))\n",
    "        if model_name in final_errors: \n",
    "            final_errors[model_name].append(error)\n",
    "        else:     \n",
    "            final_errors[model_name] = [error]\n",
    "        print model_name, \"{0:.3f}\".format(sum((y_hat-y_test)**2)/float(len(y_test))), '%'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUCCESSFULLY REDUCING COMPUTATIONAL COSTS \n",
    "\n",
    "As we note above, the error is largely unchanged, regardless of whether we use over 30 features or around 10 features. This is helpful to know as the fewer the features we use, the lower is our computational cost without much change in accuracy (more relevant in a general sense than towards this case). Below we see a comparison of mean errors produced using this data, and then we can now make some concluding statements about this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Classifier : More Features Error: 0.441 % Fewer Features Error: 0.463 %\n",
      "Random Forests : More Features Error: 0.447 % Fewer Features Error: 0.478 %\n",
      "Gradient Boosting : More Features Error: 0.444 % Fewer Features Error: 0.460 %\n",
      "Logistic Regression : More Features Error: 0.441 % Fewer Features Error: 0.463 %\n",
      "Support Vector Machines : More Features Error: 0.470 % Fewer Features Error: 0.466 %\n",
      "AdaBoost Classifier : More Features Error: 0.443 % Fewer Features Error: 0.465 %\n"
     ]
    }
   ],
   "source": [
    "for key in methods: \n",
    "    a = mean(initial_errors[key])\n",
    "    b = mean(final_errors[key])\n",
    "    print key, \": More Features Error:\", \"{0:.3f}\".format(a), \"% Fewer Features Error:\", \"{0:.3f}\".format(b), '%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOME CONCLUDING REMARKS \n",
    "\n",
    "As we notice here, the variable inputs that we have don't neccessarily help in determining which students would use our database and which students would chose not to. It almost seems like there is low predictability in who might use the database and who wouldn't. (There may be a trick or two more in the bag to resolve this issue, and I'll most certainly explore it once I've stayed away from the dataset for a reasonable amount of time.) A policy maker can approach this problem in two different ways: \n",
    "\n",
    "1. Target giving access to the database to all students instead of targeting ones that are likely to use it/figuring out ways to reach the students who won't.\n",
    "\n",
    "2. Another possible option is to expand the scope of the survey. This generates more features that could be more useful in predicting students more likely to use the database. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
